import streamlit as st
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import time
import json
from datetime import datetime
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ê–≥–µ–Ω—Ç –æ—Ü–µ–Ω–∫–∏ –∑–≤–æ–Ω–∫–æ–≤",
    page_icon="üìû", 
    layout="wide"
)

tok = AutoTokenizer.from_pretrained("cardiffnlp/twitter-roberta-base-sentiment-latest")

# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã
@st.cache_resource
def load_sentiment_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Å —É—Å–µ—á–µ–Ω–∏–µ–º –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    model_name = "cardiffnlp/twitter-roberta-base-sentiment-latest"
    device = 0 if torch.cuda.is_available() else -1
    return pipeline(
        "sentiment-analysis",
        model=model_name,
        device=device,
        return_all_scores=True,
        tokenizer=model_name,
        truncation=True,      # –æ–±—Ä–µ–∑–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        max_length=512         # –º–∞–∫—Å–∏–º—É–º 512 —Ç–æ–∫–µ–Ω–æ–≤
    )

@st.cache_resource 
def load_generation_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    model_name = "distilbert-base-uncased-finetuned-sst-2-english"

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)

    if torch.cuda.is_available():
        model = model.to('cuda')

    return tokenizer, model

def preprocess_text(text):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    # –ó–∞–º–µ–Ω–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Å—Å—ã–ª–æ–∫
    new_text = []
    for t in text.split(" "):
        t = '@user' if t.startswith('@') and len(t) > 1 else t
        t = 'http' if t.startswith('http') else t
        new_text.append(t)
    return " ".join(new_text)

def chunk_and_analyze(text, pipe, tokenizer, max_len=512, stride=448):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è —á–∞–Ω–∫–∏, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π –∏ –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç."""
    token_ids = tokenizer(text, add_special_tokens=False)["input_ids"]
    results = []
    for start in range(0, len(token_ids), stride):
        chunk_ids = token_ids[start : start + max_len]
        chunk = tokenizer.decode(chunk_ids, clean_up_tokenization_spaces=True)
        # pipe(chunk) –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç [[{label,score},‚Ä¶]]
        chunk_scores = pipe(chunk)[0]  
        # –¥–ª—è —ç—Ç–æ–≥–æ —á–∞–Ω–∫–∞ –≤—ã–±–∏—Ä–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º score
        main_chunk = max(chunk_scores, key=lambda x: x["score"])
        results.append(main_chunk)
    # –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º: –∑–¥–µ—Å—å –≤—ã–±–∏—Ä–∞–µ–º —Å–∞–º—ã–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π –ø–æ –≤—Å–µ–º —á–∞–Ω–∫–∞–º
    best = max(results, key=lambda x: x["score"])
    return best, results

def analyze_sentiment(text, model):
    processed = preprocess_text(text)
    input_ids = tok(processed)["input_ids"]
    if len(input_ids) <= 512:
        scores = model(processed)[0]  # list of dicts
        main = max(scores, key=lambda x: x["score"])
        return main, scores
    else:
        return chunk_and_analyze(processed, model, tok)

def generate_recommendations(sentiment, text):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
    recommendations = []

    if sentiment['label'] == 'NEGATIVE':
        recommendations = [
            "ü§ù –ü—Ä–æ—è–≤–∏—Ç–µ –±–æ–ª—å—à–µ —ç–º–ø–∞—Ç–∏–∏ –∫ –ø—Ä–æ–±–ª–µ–º–µ –∫–ª–∏–µ–Ω—Ç–∞",
            "‚úÖ –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —à–∞–≥–∏ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã",
            "üéØ –£—Ç–æ—á–Ω–∏—Ç–µ –¥–µ—Ç–∞–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è",
            "üìû –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é"
        ]
    elif sentiment['label'] == 'NEUTRAL':
        recommendations = [
            "üòä –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –ø–æ–∑–∏—Ç–∏–≤–∞ –≤ –æ–±—â–µ–Ω–∏–µ",
            "‚ùì –ó–∞–¥–∞–π—Ç–µ —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã –æ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—è—Ö",
            "üé™ –°–¥–µ–ª–∞–π—Ç–µ —Ä–∞–∑–≥–æ–≤–æ—Ä –±–æ–ª–µ–µ –≤–æ–≤–ª–µ–∫–∞—é—â–∏–º",
            "üí° –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏"
        ]
    else:  # POSITIVE
        recommendations = [
            "üåü –ü–æ–¥–¥–µ—Ä–∂–∏—Ç–µ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π –Ω–∞—Å—Ç—Ä–æ–π –∫–ª–∏–µ–Ω—Ç–∞",
            "üéÅ –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏ –∏–ª–∏ –ø—Ä–æ–¥—É–∫—Ç—ã",
            "üìà –£–∑–Ω–∞–π—Ç–µ –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–∞",
            "üí¨ –ü–æ–ø—Ä–æ—Å–∏—Ç–µ –æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ç–∑—ã–≤ –∏–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"
        ]

    return recommendations[:2]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ 2 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

def save_analysis_history(text, sentiment, recommendations):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –∞–Ω–∞–ª–∏–∑–∞"""
    if not os.path.exists('history'):
        os.makedirs('history')

    history_entry = {
        'timestamp': datetime.now().isoformat(),
        'text': text[:100] + "..." if len(text) > 100 else text,
        'sentiment': sentiment['label'],
        'confidence': sentiment['score'],
        'recommendations': recommendations
    }

    history_file = 'history/analysis_history.json'

    try:
        with open(history_file, 'r', encoding='utf-8') as f:
            history = json.load(f)
    except FileNotFoundError:
        history = []

    history.append(history_entry)

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø–∏—Å–µ–π
    history = history[-100:]

    with open(history_file, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üìû –ê–≥–µ–Ω—Ç –æ—Ü–µ–Ω–∫–∏ –∑–≤–æ–Ω–∫–æ–≤")
st.markdown("**–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π**")

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
    device_info = "üñ•Ô∏è CPU" if not torch.cuda.is_available() else f"üöÄ GPU ({torch.cuda.get_device_name(0)})"
    st.info(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_info}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–µ–π
    st.header("üìä –ú–æ–¥–µ–ª–∏")
    st.write("**–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:**")
    st.code("cardiffnlp/twitter-roberta-base-sentiment", language="text")

    # –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤
    if st.button("üìà –ü–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
        try:
            with open('history/analysis_history.json', 'r', encoding='utf-8') as f:
                history = json.load(f)

            if history:
                st.write(f"**–í—Å–µ–≥–æ –∞–Ω–∞–ª–∏–∑–æ–≤:** {len(history)}")
                for entry in history[-5:]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
                    sentiment_emoji = {"POSITIVE": "üòä", "NEGATIVE": "üò¢", "NEUTRAL": "üòê"}
                    st.write(f"{sentiment_emoji.get(entry['sentiment'], 'ü§î')} {entry['sentiment']} ({entry['confidence']:.1%})")
        except FileNotFoundError:
            st.write("–ò—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
if 'sentiment_model' not in st.session_state:
    with st.spinner('üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏...'):
        st.session_state.sentiment_model = load_sentiment_model()
    st.success('‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!')

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
col1, col2 = st.columns([2, 1])

with col1:
    st.header("üìù –í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö")

    # –¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞
    call_text = st.text_area(
        "–í–≤–µ–¥–∏—Ç–µ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:",
        height=200,
        placeholder="–û–ø–µ—Ä–∞—Ç–æ—Ä: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –≠—Ç–æ —Å–ª—É–∂–±–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏...\n–ö–ª–∏–µ–Ω—Ç: –ü—Ä–∏–≤–µ—Ç, —É –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –∑–∞–∫–∞–∑–æ–º..."
    )

    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    if st.button("üìã –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–º–µ—Ä"):
        example_text = """–û–ø–µ—Ä–∞—Ç–æ—Ä: –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –≠—Ç–æ —Å–ª—É–∂–±–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏. –ö–∞–∫ –¥–µ–ª–∞?
–ö–ª–∏–µ–Ω—Ç: –ü—Ä–∏–≤–µ—Ç. –£ –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –∑–∞–∫–∞–∑–æ–º. –Ø –∂–¥—É —É–∂–µ –Ω–µ–¥–µ–ª—é, –∞ —Ç–æ–≤–∞—Ä –Ω–µ –ø—Ä–∏—à–µ–ª.
–û–ø–µ—Ä–∞—Ç–æ—Ä: –ü–æ–Ω–∏–º–∞—é –≤–∞—à–µ –±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ. –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è. –ù–∞–∑–æ–≤–∏—Ç–µ –Ω–æ–º–µ—Ä –∑–∞–∫–∞–∑–∞.
–ö–ª–∏–µ–Ω—Ç: 12345. –Ø –æ—á–µ–Ω—å —Ä–∞—Å—Å—Ç—Ä–æ–µ–Ω —ç—Ç–æ–π —Å–∏—Ç—É–∞—Ü–∏–µ–π.
–û–ø–µ—Ä–∞—Ç–æ—Ä: –Ø –ø—Ä–æ–≤–µ—Ä—é —Å—Ç–∞—Ç—É—Å –∑–∞–∫–∞–∑–∞ –∏ —Ä–µ—à—É –ø—Ä–æ–±–ª–µ–º—É –≤ –∫—Ä–∞—Ç—á–∞–π—à–∏–µ —Å—Ä–æ–∫–∏."""
        st.session_state.example_text = example_text
        st.experimental_rerun()

    if 'example_text' in st.session_state:
        call_text = st.session_state.example_text
        del st.session_state.example_text

with col2:
    st.header("‚ö° –î–µ–π—Å—Ç–≤–∏—è")

    analyze_button = st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä", type="primary")

    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å"):
        st.experimental_rerun()

# –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
if analyze_button and call_text:
    with st.spinner('üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º...'):
        start_time = time.time()

        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        main_sentiment, all_sentiments = analyze_sentiment(call_text, st.session_state.sentiment_model)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = generate_recommendations(main_sentiment, call_text)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        save_analysis_history(call_text, main_sentiment, recommendations)

        end_time = time.time()
        processing_time = end_time - start_time

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    st.header("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")

    col1, col2, col3 = st.columns([1, 1, 1])

    with col1:
        # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        sentiment_colors = {
            'POSITIVE': 'green',
            'NEGATIVE': 'red',
            'NEUTRAL': 'orange'
        }

        sentiment_emojis = {
            'POSITIVE': 'üòä',
            'NEGATIVE': 'üò¢', 
            'NEUTRAL': 'üòê'
        }

        color = sentiment_colors.get(main_sentiment['label'], 'gray')
        emoji = sentiment_emojis.get(main_sentiment['label'], 'ü§î')

        st.metric(
            "–û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å",
            f"{emoji} {main_sentiment['label']}",
            f"{main_sentiment['score']:.1%}"
        )

    with col2:
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        confidence_color = "green" if main_sentiment['score'] > 0.8 else "orange" if main_sentiment['score'] > 0.6 else "red"
        st.metric(
            "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", 
            f"{main_sentiment['score']:.1%}",
            "–í—ã—Å–æ–∫–∞—è" if main_sentiment['score'] > 0.8 else "–°—Ä–µ–¥–Ω—è—è" if main_sentiment['score'] > 0.6 else "–ù–∏–∑–∫–∞—è"
        )

    with col3:
        # –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        st.metric("–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", f"{processing_time:.2f} —Å–µ–∫")

    # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –ø–æ –≤—Å–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—è–º
    st.header("üìà –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")

    sentiment_df = {
        '–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å': [],
        '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': [],
        '–ü—Ä–æ—Ü–µ–Ω—Ç': []
    }

    for sentiment in all_sentiments:
        sentiment_df['–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å'].append(f"{sentiment_emojis.get(sentiment['label'], 'ü§î')} {sentiment['label']}")
        sentiment_df['–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'].append(sentiment['score'])
        sentiment_df['–ü—Ä–æ—Ü–µ–Ω—Ç'].append(f"{sentiment['score']:.1%}")

    st.dataframe(sentiment_df, use_container_width=True)

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    st.header("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

    for i, rec in enumerate(recommendations, 1):
        st.write(f"**{i}.** {rec}")

elif analyze_button and not call_text:
    st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown("üöÄ **–õ–æ–∫–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞ –∑–≤–æ–Ω–∫–æ–≤** ‚Ä¢ –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ñ—Ñ–ª–∞–π–Ω ‚Ä¢ –ú–æ–¥–µ–ª–∏: RoBERTa + DistilBERT")
